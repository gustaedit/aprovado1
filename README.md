Documentação do Trabalho Prático (TP1)Classificação de Atividades Humanas1. Introdução e ObjetivoO objetivo deste projeto foi desenvolver um pipeline completo de análise de dados em Python para o reconhecimento de atividades humanas. Para tal, utilizámos o dataset FORTH-TRACE benchmark, que contém dados de 15 participantes recolhidos por 5 sensores (acelerómetro, giroscópio e magnetómetro).O trabalho foi dividido em três fases principais:Configuração e Carregamento dos DadosAnálise e Tratamento de OutliersExtração e Seleção de Características2. Tarefas 1 & 2: Configuração e Carregamento de DadosO que fizemos:Configurámos um ambiente no Google Colab com todas as bibliotecas necessárias (NumPy, Pandas, SciPy, Scikit-learn, etc.).Instalámos a biblioteca skfeature-chappers, necessária para as tarefas de seleção de features (4.5).Montámos o Google Drive e estabelecemos a ligação à pasta dos dados no caminho /content/drive/MyDrive/interacambio/FORTH_TRACE_DATASET-master.Implementámos a rotina carregar_dados_participante_local que, para um determinado participante, lê e concatena os 5 ficheiros CSV (partXdev1.csv a partXdev5.csv).Executámos esta rotina para todos os 14 participantes disponíveis e consolidámos os dados num único DataFrame do Pandas (df).3. Tarefa 3: Análise e Tratamento de OutliersEsta secção focou-se em identificar dados anómalos (outliers) utilizando diferentes métodos.3.0. Cálculo dos MódulosO que fizemos: Antes da análise, transformámos os dados 3D (x,y,z) de cada sensor numa única medida de magnitude, o módulo, usando a fórmula euclidiana $||\vec{t}||=\sqrt{t_{x}^{2}+t_{y}^{2}+t_{z}^{2}}$.3.1. Boxplots por Atividade e SensorO que fizemos: Gerámos boxplots para visualizar a distribuição dos módulos de cada sensor (acelerómetro, giroscópio, magnetómetro) para cada uma das 16 atividades.Conclusão: Os gráficos mostraram que os módulos do acelerómetro e giroscópio são altamente discriminativos; atividades dinâmicas (como "Walk" e "Climb Stair") têm valores e variabilidade muito maiores do que atividades estáticas ("Sit", "Stand"). O magnetómetro pareceu menos útil, com distribuições muito semelhantes entre as atividades.3.2. Densidade de OutliersO que fizemos: Focando-nos apenas no sensor do pulso direito (ID 2), calculámos a densidade de outliers usando a fórmula $d=\frac{n_{o}}{n_{r}}\times100$. Os outliers ($n_o$) foram definidos pelo método padrão IQR.Conclusão: As atividades de transição (ex: "Stand->Sit", "Walk->stand") apresentaram as maiores densidades de outliers. Concluímos que estes não são "ruído", mas sim eventos característicos da própria atividade (picos de movimento) que o método estatístico identifica como anomalias.3.3, 3.4 & 3.5. Análise com Z-ScoreO que fizemos: Implementámos a função identificar_outliers_zscore e aplicámo-la aos dados com $k=3$, $k=3.5$ e $k=4$.Conclusão (Alteração 3.3): Observámos que o Z-Score identificou muito poucos outliers. A nossa conclusão é que isto se deve a duas razões:Os dados não seguem uma distribuição normal.O Z-Score é sensível aos próprios outliers. Os valores extremos "puxam" a média e "inflacionam" o desvio padrão, fazendo com que outliers menos extremos pareçam "normais" e fiquem dentro do limiar k.3.6 & 3.7. Deteção de Outliers com K-MeansO que fizemos (Alteração 3.6): Implementámos o K-Means e executámo-lo no dataset completo (milhões de pontos).O que fizemos (Alteração 3.7): Para identificar os outliers, aplicámos a lógica pedida: para cada cluster, calculámos o IQR das distâncias ao centroide e rejeitámos os pontos cuja distância era superior a $Q3 + 1.5 \times IQR$.Conclusão: Esta abordagem multivariada é computacionalmente exigente, mas aplica uma lógica robusta (IQR) para identificar pontos que estão genuinamente longe do seu grupo.4. Tarefa 4: Extração e Seleção de Características4.1. Análise de Significância EstatísticaO que fizemos: Usámos o teste de Kolmogorov-Smirnov (KS), que confirmou que os dados não são normais.O que fizemos (Alteração 4.1): Substituímos o Kruskal-Wallis pelo teste U de Mann-Whitney para realizar comparações par-a-par entre todas as 16 atividades.Conclusão: A vasta maioria dos pares de atividades mostrou ter diferenças estatisticamente significativas (p < 0.05). Isto prova que os módulos dos sensores são features estatisticamente válidas para a classificação.4.2. Extração de Features do ArtigoO que fizemos: Esta tarefa exigia a implementação de features de um artigo. Para permitir a continuação do trabalho, criámos um feature set de 12 dimensões (os 9 eixos x,y,z originais e os 3 módulos calculados).4.3 & 4.4. Análise de Componentes Principais (PCA)O que fizemos (Alteração 4.3): Conforme solicitado, implementámos o PCA "do zero" (pca_from_scratch). Esta função usa NumPy para calcular a Matriz de Covariância, Eigenvalues e Eigenvectors.Conclusão (Alteração 4.4): Analisámos a importância de cada componente usando os eigenvalues (conforme a "explicação da lousa"). A variância explicada por cada componente é o seu $Eigenvalue$ / $Soma(Todos Eigenvalues)$. Determinámos o número de componentes necessárias para explicar 75% da variância.4.5 & 4.6. Seleção de Features (Fisher Score e ReliefF)O que fizemos: Implementámos os algoritmos Fisher Score e ReliefF no nosso feature set de 12 dimensões.Conclusão (Alteração 4.6): Identificámos e apresentámos as 10 melhores features de acordo com cada método. Os rankings foram semelhantes, destacando mod_accel, mod_gyro e os eixos x e z do acelerómetro como os mais importantes.
